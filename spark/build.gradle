project.ext.archiveName = 'spark-app.jar'

buildscript {
  repositories { jcenter() }
  dependencies {
    classpath 'com.github.jengelman.gradle.plugins:shadow:1.2.0'
  }
}

apply plugin: 'java'
apply plugin: 'maven'
apply plugin: 'eclipse'
apply plugin: 'com.github.johnrengelman.shadow'
apply plugin: 'scala'

group = 'com.mikebin'
version = '0.0.1'

description = """Spark Job"""

sourceCompatibility = 1.7
targetCompatibility = 1.7

configurations {
  provided
  compile { extendsFrom provided }
}

repositories {
  mavenCentral()
}

dependencies {
  provided "org.apache.spark:spark-core_2.10:${sparkVersion}"
  provided "org.apache.spark:spark-sql_2.10:${sparkVersion}"
  provided "org.apache.spark:spark-streaming_2.10:${sparkVersion}"
  provided "org.apache.spark:spark-streaming-kafka_2.10:${sparkVersion}"
  provided "org.apache.hadoop:hadoop-client:${hadoopVersion}"
  provided "org.apache.spark:spark-hive_2.10:${sparkVersion}"
  testCompile 'junit:junit:4.11'
  testCompile 'org.hamcrest:hamcrest-all:1.3'
}

if (project.ext.properties.containsKey("archiveName")) {
  shadowJar {
    archiveName = "${project.ext.archiveName}"
    destinationDir = new File("${project.projectDir}")
  }
}

task deleteJar(type: Delete) {
  if (project.ext.properties.containsKey("archiveName")) {
    delete "${project.ext.archiveName}"
  }
}

clean.dependsOn(deleteJar)

def excludeJars = configurations.provided.files.collect { it.name }
shadowJar {
  mergeServiceFiles()
  exclude excludeJars
}

jar {
  actions = []
}
jar.dependsOn(shadowJar)

tasks.withType(ScalaCompile) {
  scalaCompileOptions.useAnt = false
}

task wrapper(type: Wrapper) {
  gradleVersion = '2.2.1'
}
